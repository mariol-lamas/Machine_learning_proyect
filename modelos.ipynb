{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score,accuracy_score,confusion_matrix\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D,Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Reshape,TimeDistributed,Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('datos_limpios.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Estudio de importancia de variables**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_prods=[f'ind_prod{i}' for i in range(1,26)]\n",
    "data_estudio=data.drop(['cod_persona','mes','fecha1'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_estudio.drop(ind_prods,axis=1)\n",
    "y=data_estudio[ind_prods]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a emplear un modelo de clasificacion con Boosting para evaluar como considera el propio modelo que es cada variable de importante.\n",
    "\n",
    "![Modelo Catboost](https://www.researchgate.net/publication/370695897/figure/fig3/AS:11431281170540470@1687832218068/The-flow-diagram-of-the-CatBoost-model.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comenzamos haciendo la division en muestra de entrenamiento (para entrenar) y muestra de testeo (para evaluar el rendimiento del modelo entrenado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos=[]\n",
    "for idx,prod in enumerate(ind_prods):\n",
    "    if prod!='ind_prod2': #Hacemos esto porque este producto no lo compra nadie y no vamos a tratar de recomendarlo\n",
    "        modelo_catboost=CatBoostClassifier(verbose=1000)\n",
    "        modelo_catboost.fit(X_train,y_train.iloc[:,idx])\n",
    "        modelos.append(modelo_catboost)\n",
    "        y_pred = modelo_catboost.predict(X_test)\n",
    "        # Evaluar la precisión del modelo\n",
    "        accuracy = accuracy_score(y_test.iloc[:,idx], y_pred)\n",
    "        print('\\n','*'*50)\n",
    "        print('-'*50,'\\nProducto: ',prod)\n",
    "        print(f'Accuracy: {accuracy}')\n",
    "        recall = recall_score(y_test.iloc[:,idx], y_pred)\n",
    "        print(f'Recall: {recall}')\n",
    "        conf = confusion_matrix(y_test.iloc[:,idx], y_pred)\n",
    "        print(f'Matriz de confusion: {conf} ','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inicial_mod=pd.DataFrame([modelos[0].feature_importances_],columns=modelos[0].feature_names_)\n",
    "for model in modelos[1:]:\n",
    "    data_mod=pd.DataFrame([model.feature_importances_],columns=model.feature_names_)\n",
    "    data_inicial_mod=pd.concat([data_inicial_mod,data_mod])\n",
    "data_inicial_mod.median().reset_index().sort_values(0,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como conclusiones de esta primera prueba:\n",
    "- Habria que introducir una correccion del desbalanceo de clases ya que hay pocos datos cuando es 1 y muchos cuando es 0 asi que tiende a predecir 0 de mas.\n",
    "- Habria que probar tratar los datos como series temporales.\n",
    "- Las siguientes columnas podrian eliminarse ya que el modelo no las considera importantes (Seleccion de variables intrinseca): xti_rel, indext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelo red Neuronal sin Serie Temporal**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rnn=data.drop(['cod_persona','mes','fecha1','xti_rel','indext'],axis=1)\n",
    "X=data_rnn.drop(ind_prods,axis=1)\n",
    "y=data_rnn[ind_prods]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos en muestra de entrenamiento y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos los datos a tensores para que los pueda procesar la libreria TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "X_test_tensor = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "\n",
    "y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la funcion dinamica que nos permite generar muchos modelos simplemente cambiando parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_modelo(input_shape, output_shape, dense_layers=6,dense_layer_units=100, dropout_rate=0.5):\n",
    "    model = Sequential()\n",
    "    # Añadir capas Conv2D y MaxPooling2D\n",
    "    for i in range(dense_layers):\n",
    "        if i==0:\n",
    "            input_shape\n",
    "            model.add(Dense(units=dense_layer_units,activation='relu',input_dim=input_shape))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "        else:\n",
    "            model.add(Dense(units=dense_layer_units,activation='relu'))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Capa de salida\n",
    "    model.add(Dense(output_shape, activation='sigmoid'))\n",
    "    \n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy','recall','categorical_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un modelo y vemos su arquitectura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=crear_modelo(X_train_tensor.shape[-1],y_test_tensor.shape[1],dense_layers=2,dense_layer_units=20,dropout_rate=.5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos unos Callbacks para controlar la ejecucion del entrenamiento y entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, verbose=1),  # Parada temprana si la pérdida en validación deja de disminuir\n",
    "    ModelCheckpoint('modelo_epoch_{epoch:02d}.keras', save_freq='epoch', verbose=1)  # Guardar el modelo en cada época\n",
    "]\n",
    "history=model.fit(X_train_tensor,y_train_tensor,epochs=10,batch_size=16,validation_data=(X_test_tensor,y_test_tensor),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si evaluamos el modelo con los datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, recall,accuracy,cat_accuracy = model.evaluate(X_test_tensor, y_test_tensor)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}, Recall: {recall}, Cat Accuracy: {cat_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que esta red no mejora los resultados iniciales obtenidos con Catboost, probemos a ver si con series temporales mejoramos los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelo de red Neuronal con Series Temporales**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero es convertir los datos a secuencias con informacion de varios periodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_sequences(df, cod_persona_col, feature_cols, target_cols, sequence_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    targets_anteriores = []\n",
    "\n",
    "    personas = df[cod_persona_col].unique()\n",
    "\n",
    "    # Convertir el DataFrame a un numpy array para operaciones más rápidas\n",
    "    df_values = df[[cod_persona_col] + feature_cols + target_cols].values\n",
    "    cod_persona_index = 0  # El índice de cod_persona_col en df_values\n",
    "\n",
    "    for persona in personas:\n",
    "        # Filtrar las filas correspondientes a la persona actual\n",
    "        persona_mask = df_values[:, cod_persona_index] == persona\n",
    "        persona_df = df_values[persona_mask]\n",
    "        \n",
    "        # Si la longitud del DataFrame de la persona es menor que sequence_length, se omite\n",
    "        if len(persona_df) <= sequence_length:\n",
    "            continue\n",
    "        \n",
    "        for i in range(len(persona_df) - sequence_length):\n",
    "            sequence = persona_df[i:i+sequence_length, 1:1+len(feature_cols)]\n",
    "            target = persona_df[i+sequence_length, 1+len(feature_cols):1+len(feature_cols)+len(target_cols)]\n",
    "            target_anterior = persona_df[i+sequence_length-1, 1+len(feature_cols):1+len(feature_cols)+len(target_cols)]\n",
    "            sequences.append(sequence)\n",
    "            targets.append(target)\n",
    "            targets_anteriores.append(target_anterior)\n",
    "    \n",
    "    return np.array(sequences), np.array(targets), np.array(targets_anteriores)\n",
    "\n",
    "# Definir las columnas de características y de objetivos\n",
    "feature_cols = [col for col in data.columns if col.find('ind_prod')==-1 and col not in ['cod_persona','mes','fecha1','xti_rel','indext']]\n",
    "target_cols = [col for col in data.columns if col.find('ind_prod')!=-1 and col.find('ind_prod2')==-1]\n",
    "\n",
    "# Longitud de la secuencia\n",
    "sequence_length = 4  # Por ejemplo, secuencias de 5 días\n",
    "\n",
    "# Crear las secuencias\n",
    "X_seq, y_seq, y_prev_seq = create_sequences(data, 'cod_persona', feature_cols, target_cols, sequence_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos los datos y convertimos a tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = int(len(X) * 0.8)\n",
    "# Dividir los datos en entrenamiento y prueba manteniendo la temporalidad\n",
    "X_train, X_test = X_seq[:cutoff], X_seq[cutoff:]\n",
    "y_train, y_test = y_seq[:cutoff], y_seq[cutoff:]\n",
    "y_prev_train, y_prev_test = y_prev_seq[:cutoff], y_prev_seq[cutoff:]\n",
    "\n",
    "X_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "X_test_tensor = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "\n",
    "y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
    "\n",
    "y_prev_train_tensor = tf.convert_to_tensor(y_prev_train, dtype=tf.float32)\n",
    "y_prev_test_tensor = tf.convert_to_tensor(y_prev_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la funcion para generar modelos de Redes Neuronales Recurrentes.\n",
    "\n",
    "![Ejemplos de capas RNN](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_modelo_mixto(input_shape, output_shape,  lstm_units=204,dense_units=[], dropout_rate=0.5):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=lstm_units, return_sequences=True, dropout=dropout_rate, input_shape=input_shape))\n",
    "    model.add(LSTM(units=lstm_units, return_sequences=False, dropout=dropout_rate, input_shape=input_shape))\n",
    "    \n",
    "    # Añadir capas Conv2D y MaxPooling2D\n",
    "    for i in dense_units:\n",
    "        model.add(Dense(units=i,activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Capa de salida\n",
    "    model.add(Dense(output_shape, activation='sigmoid'))\n",
    "    \n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy','recall','categorical_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=crear_modelo_mixto(X_train_tensor.shape[-2:],y_test_tensor.shape[1],lstm_units=20,dense_units=[40,40,40,40,40,80,60,40],dropout_rate=.5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, verbose=1),  # Parada temprana si la pérdida en validación deja de disminuir\n",
    "    ModelCheckpoint('modelo_epoch_{epoch:02d}.keras', save_freq='epoch', verbose=1)  # Guardar el modelo en cada época\n",
    "]\n",
    "history=model.fit(X_train_tensor,y_train_tensor,epochs=2,batch_size=16,validation_data=(X_test_tensor,y_test_tensor),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vemos que no funciona muy bien, hay que tener tambien en cuenta que por cada usuario solo tenemos 16 periodos de informacion, en conclusion, el modelo final sera un Modelo Catboost aplicando el filtrado de productos por segmento y añadiremos pesos a las clases para corregir el desbalanceo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para considerar el comportamiento historico para predecir los productos vamos a añadir las compras del periodo anterior para predecir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelo Catboost Final**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, obtenemos los productos que si se han comprado por cada segmento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_segmentos=data.groupby(by=['id_segmento'])[ind_prods].sum().T.to_dict()\n",
    "diccionario_seg_proc={}\n",
    "for key,value in diccionario_segmentos.items():\n",
    "    sol=[]\n",
    "    for prod,res in value.items():\n",
    "        if res>0:\n",
    "            sol.append(prod)\n",
    "    diccionario_seg_proc[key]=sol\n",
    "diccionario_seg_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos columnas con un shift sobre el dataset inicial (Idea de competicion Kaggle)\n",
    "columnas_usar=['pais', 'sexo', 'edad', 'xti_empleado', 'xti_nuevo_cliente',\n",
    "       'num_antiguedad', 'xti_rel_1mes', 'tip_rel_1mes', 'indresi',\n",
    "       'des_canal', 'xti_extra', 'cod_provincia', 'xti_actividad_cliente',\n",
    "       'imp_renta', 'id_segmento', 'mean_engagement','edad_dividida']\n",
    "DIFF_CONDS = {}\n",
    "for shift_val in [1]:\n",
    "    name = 'id_shift_' + str(shift_val)\n",
    "    data[name] = data['cod_persona'].shift(shift_val).fillna(0).astype(np.int32)\n",
    "    DIFF_CONDS[shift_val] = ((data['cod_persona'] - data[name]) != 0)\n",
    "    data.drop(name,axis = 1,inplace=True)\n",
    "\n",
    "shifted_feature_names = []\n",
    "for col in columnas_usar + target_cols:\n",
    "    for shift_val in [1]:\n",
    "        name = col + '_s_' + str(shift_val)\n",
    "        data[name] = data[col].shift(shift_val).fillna(0).astype(np.int32)\n",
    "        data[name][DIFF_CONDS[shift_val]] = 0\n",
    "        if col in columnas_usar:\n",
    "            shifted_feature_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a añadir ademas la informacion del resto del columnas del periodo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_feautres_s1 = []\n",
    "for col in columnas_usar:\n",
    "    name = col + '_s1_diff'\n",
    "    diff_feautres_s1.append(name)\n",
    "    data[name] = (data[col] - data[col + '_s_1']).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear nuevas columnas (Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Antiguedad minima del usuario\n",
    "MIN_ANTIGUEDAD_DICT = data.groupby('cod_persona')['num_antiguedad'].min().to_dict()\n",
    "data['min_antiguedad'] = data['cod_persona'].map(lambda x: MIN_ANTIGUEDAD_DICT[x]).astype(np.int16)\n",
    "\n",
    "#Antiguedad maxima del usuario\n",
    "MAX_ANTIGUEDAD_DICT = data.groupby('cod_persona')['num_antiguedad'].max().to_dict()\n",
    "data['max_antiguedad'] = data['cod_persona'].map(lambda x: MAX_ANTIGUEDAD_DICT[x]).astype(np.int16)\n",
    "\n",
    "#Edad minima del usuario\n",
    "MIN_AGE_DICT = data.groupby('cod_persona')['edad'].min().to_dict()\n",
    "data['min_edad'] = data['cod_persona'].map(lambda x: MIN_AGE_DICT[x]).astype(np.int16)\n",
    "\n",
    "#Edad maxima del usuario\n",
    "MAX_AGE_DICT = data.groupby('cod_persona')['edad'].max().to_dict()\n",
    "data['max_edad'] = data['cod_persona'].map(lambda x: MAX_AGE_DICT[x]).astype(np.int16)\n",
    "\n",
    "#Minimo maximo y desviancion estandar de la renta por cada usuario\n",
    "MIN_RENTA_DICT = data.groupby('cod_persona')['imp_renta'].min().to_dict()\n",
    "data['min_renta'] = data['cod_persona'].map(lambda x: MIN_RENTA_DICT[x])\n",
    "MAX_RENTA_DICT = data.groupby('cod_persona')['imp_renta'].max().to_dict()\n",
    "data['max_renta'] = data['cod_persona'].map(lambda x: MAX_RENTA_DICT[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RENTA_VAL_COUNTS = data.groupby('imp_renta')['cod_persona'].nunique().to_dict()\n",
    "data['renta_freq'] = data['imp_renta'].map(lambda x: RENTA_VAL_COUNTS[x])\n",
    "data.sort_values(by = ['cod_persona','mes'],inplace=True)\n",
    "#Eliminamos los id duplicados porque hemos reducido la informacion a una sola fila por usuario\n",
    "data_lista = data.drop_duplicates('cod_persona')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lista.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vemos que al final hemos pasado de 600mil datos a 47mil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El siguiente paso es entrenar los diferentes modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "acc=[]\n",
    "rec=[]\n",
    "for idx,prod in enumerate(ind_prods):\n",
    "    if prod!='ind_prod2':\n",
    "        X=data_lista[columnas_usar].copy()\n",
    "        y=data_lista[prod].copy()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        # Identificar características categóricas\n",
    "        categorical_features_indices = np.where(X.dtypes != np.float64)[0]\n",
    "        # Calcular los pesos de las clases para tratar de corregir el desbalanceo\n",
    "        class_weights = [len(y) / (2 * sum(y == c)) for c in y.unique()]\n",
    "\n",
    "        # Crear el modelo CatBostClassifier con pesos \n",
    "        modelo = CatBoostClassifier(\n",
    "            loss_function='Logloss',\n",
    "            class_weights=class_weights,\n",
    "            verbose=1000)\n",
    "\n",
    "        # Entrenar el modelo\n",
    "        modelo.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modelo.predict(X_test)\n",
    "        models.append(modelo)\n",
    "        # Evaluar la precisión del modelo\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        acc.append(accuracy)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        rec.append(recall)\n",
    "        conf = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        print('-'*50,'\\nProducto: ',prod)\n",
    "        print(f'Accuracy: {accuracy}')\n",
    "        print(f'Recall: {recall}')\n",
    "        print(f'Matriz de confusion: {conf} ','\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptamos los datos para hacer la prediccion al futuro (recomendacion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prods_anterior=[f'ind_prod{i}_s_1' for i in range(1,26)]\n",
    "data_para_predecir=data_lista.copy()\n",
    "data_para_predecir.reset_index(inplace=True)\n",
    "for i in range(1,26):\n",
    "    data_para_predecir[f'ind_prod{i}_s_1']=data_para_predecir[f'ind_prod{i}']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empleando los modelos, realizamos las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones={}\n",
    "\n",
    "for model,prod in zip(models,ind_prods):\n",
    "    predicciones[prod]=list(model.predict_proba(data_para_predecir[columnas_usar])[:,1])\n",
    "predicciones['ind_prod2']=np.zeros(data_para_predecir[columnas_usar].shape[0])\n",
    "predicciones['cod_persona']=data_para_predecir['cod_persona'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data=pd.DataFrame(predicciones).set_index('cod_persona')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos las columnas que superan un umbral en orden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umbral = 0.5\n",
    "\n",
    "# Función para obtener la lista ordenada de columnas según el segundo valor que supera el umbral\n",
    "def row_to_ordered_dict(row):\n",
    "    row_dict = row.to_dict()\n",
    "    sorted_dict = dict(sorted(row_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    return sorted_dict\n",
    "\n",
    "# Crear una nueva columna con los diccionarios ordenados\n",
    "pred_data['predicted'] = pred_data.apply(row_to_ordered_dict, axis=1)\n",
    "pred_data['predicted']= pred_data['predicted'].apply(lambda x: [k for k,val in x.items() if (val>.5) & (k!='id')] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalmente guardamos nuestras recomendaciones!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.to_csv('soluciones.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entorno_prueba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
